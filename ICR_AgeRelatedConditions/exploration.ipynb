{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ffd7e-ba82-4283-aa50-fc01288e77d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a892e134-a07a-4b57-a214-2fb2cfc5f2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dbaaee5-9688-450a-8c01-440a7ad39cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "greeks = pd.read_csv('Data/greeks.csv')\n",
    "sub = pd.read_csv('Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99f84061-c7e1-40aa-a2d5-34305da007c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "\n",
    "train['EJ'] = LE.fit_transform(train['EJ'])\n",
    "test['EJ'] = LE.transform(test['EJ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cbcf9-18d1-4149-86b9-c48d82653f30",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94471f06-22ec-432a-8ff6-7bfdf91e026f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2467046-ae13-4071-ad6b-813cc1a65659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13ee75-ea6f-4274-9836-1d11ca6a8a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greeks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a67e4f-c752-45d0-a27a-1413a6e678eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(greeks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72773e-69a1-4031-808a-00ed17f36272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing = train.isna().sum().reset_index()\n",
    "missing.columns = ['columns', 'missing_count']\n",
    "missing.sort_values('missing_count', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df852880-ba78-4bbb-87d5-02e0322d2c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['Id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d407bd4-db56-42f5-8dee-7ad32ad06225",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f30bcb66-bfa7-4224-8cfb-1bbf6b2b56eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining the input and target variables\n",
    "X = train.drop(columns = ['Class'])\n",
    "Y = train['Class']\n",
    "\n",
    "## Splitting the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y)\n",
    "\n",
    "## Re-defining the training set\n",
    "train = pd.concat([X_train, Y_train], axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f499729-daf0-44a7-8368-b39f278b5e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Fold 1 ==> LightGBM oof log-loss is ==> 0.23197055888916274\n",
      "Fold 1 ==> XGBoost oof log-loss is ==> 0.20710055509866743\n",
      "Fold 1 ==> CatBoost oof log-loss is ==> 0.20926145602751287\n",
      "Fold 1 ==> Ensemble oof log-loss is ==> 0.07520874031829519\n",
      "---------------------------------------------\n",
      "Fold 2 ==> LightGBM oof log-loss is ==> 0.0999441092159285\n",
      "Fold 2 ==> XGBoost oof log-loss is ==> 0.06309621669389436\n",
      "Fold 2 ==> CatBoost oof log-loss is ==> 0.12051072686411989\n",
      "Fold 2 ==> Ensemble oof log-loss is ==> 0.02312977211400287\n",
      "---------------------------------------------\n",
      "Fold 3 ==> LightGBM oof log-loss is ==> 0.25235316293518595\n",
      "Fold 3 ==> XGBoost oof log-loss is ==> 0.18712614108873954\n",
      "Fold 3 ==> CatBoost oof log-loss is ==> 0.16386238226912275\n",
      "Fold 3 ==> Ensemble oof log-loss is ==> 0.03498209736996718\n",
      "---------------------------------------------\n",
      "Fold 4 ==> LightGBM oof log-loss is ==> 0.2458691130105267\n",
      "Fold 4 ==> XGBoost oof log-loss is ==> 0.20436745605523546\n",
      "Fold 4 ==> CatBoost oof log-loss is ==> 0.18808203428137196\n",
      "Fold 4 ==> Ensemble oof log-loss is ==> 0.06177963972907903\n",
      "---------------------------------------------\n",
      "Fold 5 ==> LightGBM oof log-loss is ==> 0.1911642565662856\n",
      "Fold 5 ==> XGBoost oof log-loss is ==> 0.26172735848827633\n",
      "Fold 5 ==> CatBoost oof log-loss is ==> 0.18771848763829055\n",
      "Fold 5 ==> Ensemble oof log-loss is ==> 0.030763878198253637\n",
      "---------------------------------------------\n",
      "Fold 6 ==> LightGBM oof log-loss is ==> 0.4290156415223178\n",
      "Fold 6 ==> XGBoost oof log-loss is ==> 0.49851190092417613\n",
      "Fold 6 ==> CatBoost oof log-loss is ==> 0.3323584832941593\n",
      "Fold 6 ==> Ensemble oof log-loss is ==> 0.10931008991550752\n",
      "---------------------------------------------\n",
      "Fold 7 ==> LightGBM oof log-loss is ==> 0.29329354068701596\n",
      "Fold 7 ==> XGBoost oof log-loss is ==> 0.35098526167970096\n",
      "Fold 7 ==> CatBoost oof log-loss is ==> 0.17493451304558782\n",
      "Fold 7 ==> Ensemble oof log-loss is ==> 0.06237113181884784\n",
      "---------------------------------------------\n",
      "Fold 8 ==> LightGBM oof log-loss is ==> 0.14450566203280216\n",
      "Fold 8 ==> XGBoost oof log-loss is ==> 0.16272005215222798\n",
      "Fold 8 ==> CatBoost oof log-loss is ==> 0.15718393085197938\n",
      "Fold 8 ==> Ensemble oof log-loss is ==> 0.044019090706762506\n",
      "---------------------------------------------\n",
      "Fold 9 ==> LightGBM oof log-loss is ==> 0.15474692981239124\n",
      "Fold 9 ==> XGBoost oof log-loss is ==> 0.16585780405491696\n",
      "Fold 9 ==> CatBoost oof log-loss is ==> 0.15161697053752837\n",
      "Fold 9 ==> Ensemble oof log-loss is ==> 0.054011804852497146\n",
      "---------------------------------------------\n",
      "Fold 10 ==> LightGBM oof log-loss is ==> 0.12037108326682847\n",
      "Fold 10 ==> XGBoost oof log-loss is ==> 0.2099248414137802\n",
      "Fold 10 ==> CatBoost oof log-loss is ==> 0.13974620658684198\n",
      "Fold 10 ==> Ensemble oof log-loss is ==> 0.026507561961795344\n"
     ]
    }
   ],
   "source": [
    "## Defining the input and target variables\n",
    "X = train.drop(columns = ['Id', 'Class'], axis = 1)\n",
    "Y = train['Class']\n",
    "\n",
    "X_test = X_test.drop(columns = ['Id'], axis = 1)\n",
    "\n",
    "## Defining lists to store results\n",
    "lgbm_cv_scores, lgbm_preds = list(), list()\n",
    "xgb_cv_scores, xgb_preds = list(), list()\n",
    "cat_cv_scores, cat_preds = list(), list()\n",
    "ens_cv_scores, ens_preds = list(), list()\n",
    "\n",
    "## Performing KFold cross-validation\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "    \n",
    "for i, (train_idx, valid_idx) in enumerate(skf.split(X, Y)):\n",
    "        \n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    Y_train, Y_valid = Y.iloc[train_idx], Y.iloc[valid_idx]\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    ## LightGBM\n",
    "    lgbm_md = LGBMClassifier(objective = 'binary', class_weight = 'balanced', verbosity = -1, \n",
    "                            metric = 'binary_logloss').fit(X_train, Y_train)\n",
    "    \n",
    "    lgbm_pred_valid = lgbm_md.predict_proba(X_valid)   \n",
    "    lgbm_pred_test = lgbm_md.predict_proba(X_test)  \n",
    "    \n",
    "    lgbm_score_fold = log_loss(Y_valid, lgbm_pred_valid)\n",
    "    \n",
    "    lgbm_cv_scores.append(lgbm_score_fold)\n",
    "    lgbm_preds.append(lgbm_pred_test)\n",
    "    \n",
    "    print('Fold', i+1, '==> LightGBM oof log-loss is ==>', lgbm_score_fold)\n",
    "    \n",
    "    ## XGBoost\n",
    "    xgb_md = XGBClassifier(objective = 'binary:logistic', scale_pos_weight = 4.71, verbosity = 0).fit(X_train, Y_train)\n",
    "        \n",
    "    xgb_pred_valid = xgb_md.predict_proba(X_valid)   \n",
    "    xgb_pred_test = xgb_md.predict_proba(X_test)  \n",
    "    \n",
    "    xgb_score_fold = log_loss(Y_valid, xgb_pred_valid)\n",
    "    \n",
    "    xgb_cv_scores.append(xgb_score_fold)\n",
    "    xgb_preds.append(xgb_pred_test)\n",
    "    \n",
    "    print('Fold', i+1, '==> XGBoost oof log-loss is ==>', xgb_score_fold)\n",
    "    \n",
    "    ## CatBoost\n",
    "    cat_md = CatBoostClassifier(auto_class_weights = 'Balanced', verbose = False).fit(X_train, Y_train)\n",
    "        \n",
    "    cat_pred_valid = cat_md.predict_proba(X_valid)   \n",
    "    cat_pred_test = cat_md.predict_proba(X_test)  \n",
    "    \n",
    "    cat_score_fold = log_loss(Y_valid, cat_pred_valid)\n",
    "    \n",
    "    cat_cv_scores.append(cat_score_fold)\n",
    "    cat_preds.append(cat_pred_test)\n",
    "    \n",
    "    print('Fold', i+1, '==> CatBoost oof log-loss is ==>', cat_score_fold)\n",
    "    \n",
    "    ## Ensemble\n",
    "    X_train_ens = pd.DataFrame({'LGBM': lgbm_pred_valid[:,1].tolist(),  \n",
    "                                'XGB': xgb_pred_valid[:,1].tolist(), \n",
    "                                'CAT': cat_pred_valid[:,1].tolist()})\n",
    "    X_test_ens = pd.DataFrame({'LGBM': lgbm_pred_test[:,1].tolist(), \n",
    "                               'XGB': xgb_pred_test[:,1].tolist(), \n",
    "                               'CAT': cat_pred_test[:,1].tolist()})\n",
    "    \n",
    "    ens_md = RandomForestClassifier(max_depth = 3, n_estimators = 100, max_features = None).fit(X_train_ens, Y_valid)\n",
    "    \n",
    "    ens_pred_valid = ens_md.predict_proba(X_train_ens)\n",
    "    ens_pred_test = ens_md.predict_proba(X_test_ens)  \n",
    "    \n",
    "    ens_score_fold = log_loss(Y_valid, ens_pred_valid)\n",
    "    \n",
    "    ens_cv_scores.append(ens_score_fold)\n",
    "    ens_preds.append(ens_pred_test)\n",
    "    \n",
    "    print('Fold', i+1, '==> Ensemble oof log-loss is ==>', ens_score_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6c7033d-8d6e-45e0-bcde-10f8953064e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM test log-loss is ==> 0.1629458584464075\n",
      "XGBoost test log-loss is ==> 0.186683319208035\n",
      "CatBoost test log-loss is ==> 0.1820564525750845\n",
      "Ensemble test log-loss is ==> 0.18342686305637823\n"
     ]
    }
   ],
   "source": [
    "lgbm_preds_test = np.mean(lgbm_preds, axis = 0).tolist()\n",
    "xgb_preds_test = np.mean(xgb_preds, axis = 0).tolist()\n",
    "cat_preds_test = np.mean(cat_preds, axis = 0).tolist()\n",
    "ens_preds_test = np.mean(ens_preds, axis = 0).tolist()\n",
    "\n",
    "print('LightGBM test log-loss is ==>', log_loss(Y_test, lgbm_preds_test))\n",
    "print('XGBoost test log-loss is ==>', log_loss(Y_test, xgb_preds_test))\n",
    "print('CatBoost test log-loss is ==>', log_loss(Y_test, cat_preds_test))\n",
    "print('Ensemble test log-loss is ==>', log_loss(Y_test, ens_preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a669d1-7912-4798-9951-e4a14094d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving best predictions as a data-frame\n",
    "predictions = pd.DataFrame(best_preds_test, , columns = ['class_0', 'class_1'])\n",
    "\n",
    "## Finalizing submissions data file\n",
    "sub['class_0'] = predictions['class_0']\n",
    "sub['class_1'] = predictions['class_1']\n",
    "\n",
    "sub.to_csv('submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
