{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ffd7e-ba82-4283-aa50-fc01288e77d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install xgboost lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a892e134-a07a-4b57-a214-2fb2cfc5f2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dbaaee5-9688-450a-8c01-440a7ad39cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/train.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "greeks = pd.read_csv('Data/greeks.csv')\n",
    "sub = pd.read_csv('Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99f84061-c7e1-40aa-a2d5-34305da007c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LE = LabelEncoder()\n",
    "\n",
    "train['EJ'] = LE.fit_transform(train['EJ'])\n",
    "test['EJ'] = LE.transform(test['EJ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cbcf9-18d1-4149-86b9-c48d82653f30",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94471f06-22ec-432a-8ff6-7bfdf91e026f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2467046-ae13-4071-ad6b-813cc1a65659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13ee75-ea6f-4274-9836-1d11ca6a8a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "greeks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a67e4f-c752-45d0-a27a-1413a6e678eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(greeks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f72773e-69a1-4031-808a-00ed17f36272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing = train.isna().sum().reset_index()\n",
    "missing.columns = ['columns', 'missing_count']\n",
    "missing.sort_values('missing_count', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df852880-ba78-4bbb-87d5-02e0322d2c0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['Id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d407bd4-db56-42f5-8dee-7ad32ad06225",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f30bcb66-bfa7-4224-8cfb-1bbf6b2b56eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Defining the input and target variables\n",
    "X = train.drop(columns = ['Class'])\n",
    "Y = train['Class']\n",
    "\n",
    "## Splitting the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = Y)\n",
    "\n",
    "## Re-defining the training set\n",
    "train = pd.concat([X_train, Y_train], axis = 1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f499729-daf0-44a7-8368-b39f278b5e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Fold 1 ==> LightGBM oof log-loss is ==> 0.14343543953914592\n",
      "Fold 1 ==> XGBoost oof log-loss is ==> 0.225352458533455\n",
      "Fold 1 ==> CatBoost oof log-loss is ==> 0.3255159161458812\n",
      "Fold 1 ==> Ensemble oof log-loss is ==> 0.03982796485434213\n",
      "---------------------------------------------\n",
      "Fold 2 ==> LightGBM oof log-loss is ==> 0.2432794156908529\n",
      "Fold 2 ==> XGBoost oof log-loss is ==> 0.26011152687521927\n",
      "Fold 2 ==> CatBoost oof log-loss is ==> 0.41851876977805386\n",
      "Fold 2 ==> Ensemble oof log-loss is ==> 0.06589669194571816\n",
      "---------------------------------------------\n",
      "Fold 3 ==> LightGBM oof log-loss is ==> 0.1752846723072354\n",
      "Fold 3 ==> XGBoost oof log-loss is ==> 0.25632118282197724\n",
      "Fold 3 ==> CatBoost oof log-loss is ==> 0.2011814201971788\n",
      "Fold 3 ==> Ensemble oof log-loss is ==> 0.046108104383013944\n",
      "---------------------------------------------\n",
      "Fold 4 ==> LightGBM oof log-loss is ==> 0.19035620715731522\n",
      "Fold 4 ==> XGBoost oof log-loss is ==> 0.2995911910128567\n",
      "Fold 4 ==> CatBoost oof log-loss is ==> 0.2601363180188012\n",
      "Fold 4 ==> Ensemble oof log-loss is ==> 0.06175859763255801\n",
      "---------------------------------------------\n",
      "Fold 5 ==> LightGBM oof log-loss is ==> 0.2112504915725459\n",
      "Fold 5 ==> XGBoost oof log-loss is ==> 0.2599910879966583\n",
      "Fold 5 ==> CatBoost oof log-loss is ==> 0.3690510521576796\n",
      "Fold 5 ==> Ensemble oof log-loss is ==> 0.08065884603089543\n",
      "---------------------------------------------\n",
      "Fold 6 ==> LightGBM oof log-loss is ==> 0.1509722529546763\n",
      "Fold 6 ==> XGBoost oof log-loss is ==> 0.19807548130059602\n",
      "Fold 6 ==> CatBoost oof log-loss is ==> 0.3466415564689371\n",
      "Fold 6 ==> Ensemble oof log-loss is ==> 0.07040820713594087\n",
      "---------------------------------------------\n",
      "Fold 7 ==> LightGBM oof log-loss is ==> 0.1410327132361447\n",
      "Fold 7 ==> XGBoost oof log-loss is ==> 0.2568907605354833\n",
      "Fold 7 ==> CatBoost oof log-loss is ==> 0.07091941051808325\n",
      "Fold 7 ==> Ensemble oof log-loss is ==> 0.025387244918641794\n",
      "---------------------------------------------\n",
      "Fold 8 ==> LightGBM oof log-loss is ==> 0.133611929786854\n",
      "Fold 8 ==> XGBoost oof log-loss is ==> 0.15645051515141079\n",
      "Fold 8 ==> CatBoost oof log-loss is ==> 0.2039960777621614\n",
      "Fold 8 ==> Ensemble oof log-loss is ==> 0.021818172163755648\n",
      "---------------------------------------------\n",
      "Fold 9 ==> LightGBM oof log-loss is ==> 0.24709090428275501\n",
      "Fold 9 ==> XGBoost oof log-loss is ==> 0.3162305416780078\n",
      "Fold 9 ==> CatBoost oof log-loss is ==> 0.4279790656436576\n",
      "Fold 9 ==> Ensemble oof log-loss is ==> 0.11531344441328761\n",
      "---------------------------------------------\n",
      "Fold 10 ==> LightGBM oof log-loss is ==> 0.2492548529678241\n",
      "Fold 10 ==> XGBoost oof log-loss is ==> 0.2795808619414396\n",
      "Fold 10 ==> CatBoost oof log-loss is ==> 0.32886159289607914\n",
      "Fold 10 ==> Ensemble oof log-loss is ==> 0.035399803102395794\n"
     ]
    }
   ],
   "source": [
    "## Defining the input and target variables\n",
    "X = train.drop(columns = ['Id', 'Class'], axis = 1)\n",
    "Y = train['Class']\n",
    "\n",
    "X_test = X_test.drop(columns = ['Id'], axis = 1)\n",
    "\n",
    "## Defining lists to store results\n",
    "lgbm_cv_scores, lgbm_preds = list(), list()\n",
    "xgb_cv_scores, xgb_preds = list(), list()\n",
    "cat_cv_scores, cat_preds = list(), list()\n",
    "ens_cv_scores, ens_preds = list(), list()\n",
    "\n",
    "## Performing KFold cross-validation\n",
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "    \n",
    "for i, (train_idx, valid_idx) in enumerate(skf.split(X, Y)):\n",
    "        \n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    Y_train, Y_valid = Y.iloc[train_idx], Y.iloc[valid_idx]\n",
    "    \n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    ## LightGBM\n",
    "    lgbm_md = LGBMClassifier(n_estimators = 1000, \n",
    "                             max_depth = 10, \n",
    "                             learning_rate = 0.01, \n",
    "                             num_leaves = 70, \n",
    "                             reg_alpha = 3, \n",
    "                             reg_lambda = 3, \n",
    "                             subsample = 0.7, \n",
    "                             colsample_bytree = 0.7, \n",
    "                             objective = 'binary', \n",
    "                             n_jobs = -1, \n",
    "                             is_unbalance = True, \n",
    "                             verbosity = -1, \n",
    "                             metric = 'binary_logloss').fit(X_train, Y_train)\n",
    "    \n",
    "    lgbm_pred_valid = lgbm_md.predict_proba(X_valid)\n",
    "    lgbm_pred_test = lgbm_md.predict_proba(X_test)\n",
    "    \n",
    "    lgbm_score_fold = log_loss(Y_valid, lgbm_pred_valid)\n",
    "    \n",
    "    lgbm_cv_scores.append(lgbm_score_fold)\n",
    "    lgbm_preds.append(lgbm_pred_test)\n",
    "    \n",
    "    print('Fold', i+1, '==> LightGBM oof log-loss is ==>', lgbm_score_fold)\n",
    "    \n",
    "    ## XGBoost\n",
    "    xgb_md = XGBClassifier(colsample_bytree = 0.7, \n",
    "                           gamma = 0.8, \n",
    "                           learning_rate = 0.01, \n",
    "                           max_depth = 8, \n",
    "                           min_child_weight = 20, \n",
    "                           n_estimators = 1000, \n",
    "                           subsample = 0.7,\n",
    "                           objective = 'binary:logistic', \n",
    "                           eval_metric = 'logloss',\n",
    "                           scale_pos_weight = 4.7, \n",
    "                           verbosity = 0).fit(X_train, Y_train)\n",
    "        \n",
    "    xgb_pred_valid = xgb_md.predict_proba(X_valid)\n",
    "    xgb_pred_test = xgb_md.predict_proba(X_test)\n",
    "    \n",
    "    xgb_score_fold = log_loss(Y_valid, xgb_pred_valid)\n",
    "    \n",
    "    xgb_cv_scores.append(xgb_score_fold)\n",
    "    xgb_preds.append(xgb_pred_test)\n",
    "    \n",
    "    print('Fold', i+1, '==> XGBoost oof log-loss is ==>', xgb_score_fold)\n",
    "    \n",
    "    ## CatBoost\n",
    "    cat_md = CatBoostClassifier(loss_function = 'Logloss', \n",
    "                                iterations = 1000, \n",
    "                                learning_rate = 0.08, \n",
    "                                depth = 10,  \n",
    "                                random_strength = 0.2, \n",
    "                                bagging_temperature = 0.7, \n",
    "                                border_count = 254, \n",
    "                                l2_leaf_reg = 0.001, \n",
    "                                verbose = False, \n",
    "                                grow_policy = 'Lossguide', \n",
    "                                eval_metric = 'Logloss', \n",
    "                                auto_class_weights = 'Balanced').fit(X_train, Y_train)\n",
    "                               \n",
    "        \n",
    "    cat_pred_valid = cat_md.predict_proba(X_valid)\n",
    "    cat_pred_test = cat_md.predict_proba(X_test)\n",
    "    \n",
    "    cat_score_fold = log_loss(Y_valid, cat_pred_valid)\n",
    "    \n",
    "    cat_cv_scores.append(cat_score_fold)\n",
    "    cat_preds.append(cat_pred_test)\n",
    "    \n",
    "    print('Fold', i+1, '==> CatBoost oof log-loss is ==>', cat_score_fold)\n",
    "    \n",
    "    ## Ensemble\n",
    "    X_train_ens = pd.DataFrame({'LGBM': lgbm_pred_valid[:,1].tolist(),  \n",
    "                                'XGB': xgb_pred_valid[:,1].tolist(), \n",
    "                                'CAT': cat_pred_valid[:,1].tolist()})\n",
    "    X_test_ens = pd.DataFrame({'LGBM': lgbm_pred_test[:,1].tolist(), \n",
    "                               'XGB': xgb_pred_test[:,1].tolist(), \n",
    "                               'CAT': cat_pred_test[:,1].tolist()})\n",
    "    \n",
    "    ens_md = RandomForestClassifier(max_depth = 3, \n",
    "                                    n_estimators = 100, \n",
    "                                    max_features = None, \n",
    "                                   criterion = 'log_loss').fit(X_train_ens, Y_valid)\n",
    "    \n",
    "    ens_pred_valid = ens_md.predict_proba(X_train_ens)\n",
    "    ens_pred_test = ens_md.predict_proba(X_test_ens)\n",
    "    \n",
    "    ens_score_fold = log_loss(Y_valid, ens_pred_valid)\n",
    "    \n",
    "    ens_cv_scores.append(ens_score_fold)\n",
    "    ens_preds.append(ens_pred_test)\n",
    "    \n",
    "    print('Fold', i+1, '==> Ensemble oof log-loss is ==>', ens_score_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c7033d-8d6e-45e0-bcde-10f8953064e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM test log-loss is ==> 0.20424829045194257\n",
      "XGBoost test log-loss is ==> 0.2472473027738288\n",
      "CatBoost test log-loss is ==> 0.22661640843392944\n",
      "Ensemble test log-loss is ==> 0.2159755328644027\n"
     ]
    }
   ],
   "source": [
    "lgbm_preds_test = np.mean(lgbm_preds, axis = 0).tolist()\n",
    "xgb_preds_test = np.mean(xgb_preds, axis = 0).tolist()\n",
    "cat_preds_test = np.mean(cat_preds, axis = 0).tolist()\n",
    "ens_preds_test = np.mean(ens_preds, axis = 0).tolist()\n",
    "\n",
    "print('LightGBM test log-loss is ==>', log_loss(Y_test, lgbm_preds_test))\n",
    "print('XGBoost test log-loss is ==>', log_loss(Y_test, xgb_preds_test))\n",
    "print('CatBoost test log-loss is ==>', log_loss(Y_test, cat_preds_test))\n",
    "print('Ensemble test log-loss is ==>', log_loss(Y_test, ens_preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66a669d1-7912-4798-9951-e4a14094d79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving best predictions as a data-frame\n",
    "predictions = pd.DataFrame(lgbm_preds_test, columns = ['class_0', 'class_1'])\n",
    "\n",
    "## Finalizing submissions data file\n",
    "sub['class_0'] = predictions['class_0']\n",
    "sub['class_1'] = predictions['class_1']\n",
    "\n",
    "sub.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91fb5ca-52d5-4704-946e-670400fe34cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
